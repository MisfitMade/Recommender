{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# These importing lines pull in the Recommender_Lib from folders above this file\n",
    "from DataAugmentation_Lib import *\n",
    "\n",
    "# These importing lines pull in env installed libs\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read each .dat file into a DF and give them col headers to match the .csv 25 mil data sets\n",
    "'''\n",
    "ratings_1M_df = pd.read_table(\n",
    "    PATH_TO_MOVIE_LENS_1M_RATINGS,\n",
    "    sep=MOVIE_LENS_1M_DELIM, # sep=\"::\"\n",
    "    header=None, # tell the read that the data has no col headers\n",
    "    engine=\"python\") # explicit use of python engine to use > 1 length sep (\"::\") without a warning\n",
    "ratings_1M_df.columns = MOVIE_LENS_25M_RATINGS_COLS\n",
    "\n",
    "ratings_25M_df = pd.read_csv(PATH_TO_MOVIE_LENS_25M_RATINGS)\n",
    "\n",
    "users_df = pd.read_table(\n",
    "    PATH_TO_MOVIE_LENS_1M_USERS,\n",
    "    sep=MOVIE_LENS_1M_DELIM,\n",
    "    header=None,\n",
    "    engine=\"python\")\n",
    "users_df.columns = MOVIE_LENS_1M_USERS_COLS\n",
    "\n",
    "movies_1M_df = pd.read_table(\n",
    "    PATH_TO_MOVIE_LENS_1M_MOVIES,\n",
    "    sep=MOVIE_LENS_1M_DELIM,\n",
    "    header=None,\n",
    "    engine=\"python\",\n",
    "    encoding=\"ISO-8859-1\") # default utf8 encoding fails during read of movies data.\n",
    "movies_1M_df.columns = MOVIE_LENS_25M_MOVIES_COLS\n",
    "\n",
    "movies_25M_df = pd.read_csv(PATH_TO_MOVIE_LENS_25M_MOVIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine the movies DFs. Need to change the 1M movie IDs so we can tell them apart later by\n",
    "adding the highest movie ID in the 25M to each. Then concat the movies in the 1M DF that are\n",
    "not in the 25M DF to the end of the 25M Df\n",
    "'''\n",
    "max_25M_movie_id = movies_25M_df[MOVIE_LENS_25M_MOVIE_ID_COL].max()\n",
    "add_max_movie_id = lambda id: id + max_25M_movie_id\n",
    "movies_1M_df[MOVIE_LENS_25M_MOVIE_ID_COL] = movies_1M_df[MOVIE_LENS_25M_MOVIE_ID_COL].map(\n",
    "    add_max_movie_id)\n",
    "ratings_1M_df[MOVIE_LENS_25M_MOVIE_ID_COL] = ratings_1M_df[MOVIE_LENS_25M_MOVIE_ID_COL].map(\n",
    "    add_max_movie_id)\n",
    "\n",
    "movies_df = pd.concat(\n",
    "    [movies_25M_df,\n",
    "    movies_1M_df[~movies_1M_df[MOVIE_LENS_25M_MOVIE_TITLE_COL].isin(\n",
    "        movies_25M_df[MOVIE_LENS_25M_MOVIE_TITLE_COL])]],\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now need to change the 1M user IDs in all DFs that have userIds so that I can tell them apart\n",
    "from the 25M user IDs. Then combine them and fill in the blanks with 0s.\n",
    "'''\n",
    "total_25M_users = len(ratings_25M_df[MOVIE_LENS_25M_USER_ID_COL].unique())\n",
    "add_max_user_id = lambda x: x + total_25M_users\n",
    "users_df[MOVIE_LENS_25M_USER_ID_COL] = users_df[MOVIE_LENS_25M_USER_ID_COL].map(\n",
    "    add_max_user_id)\n",
    "ratings_1M_df[MOVIE_LENS_25M_USER_ID_COL] = ratings_1M_df[MOVIE_LENS_25M_USER_ID_COL].map(\n",
    "    add_max_user_id)\n",
    "\n",
    "users_df = pd.concat([pd.DataFrame({\n",
    "    MOVIE_LENS_25M_USER_ID_COL : ratings_25M_df[MOVIE_LENS_25M_USER_ID_COL].unique()\n",
    "    }),\n",
    "    users_df],\n",
    "    ignore_index=True).fillna(0)\n",
    "ratings_df = pd.concat([ratings_25M_df, ratings_1M_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse row count =  0  and sparse col count =  0\n",
      "Total users:  168581 \n",
      "Total movies:  62967\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define some variables that will help us load stuff later and make decisions below\n",
    "'''\n",
    "total_users = users_df.shape[0]\n",
    "total_movies = movies_df.shape[0]\n",
    "reindexer = np.arange(1, total_users+1)\n",
    "'''\n",
    "Give a function to the SparseMatrixMaker to check for bad data so that if the ratings\n",
    "data matrix gets outof the range of the ratings numbers, 0.0 - 5.0, then an exception\n",
    "will throw, because something is broken.\n",
    "'''\n",
    "sparse_mat_maker = SparseMatrixMaker(bad_data_detector=(True, lambda d: d < 0.0 or d > 5.0))\n",
    "print(\"Total users: \", total_users, \"\\nTotal movies: \", total_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row coords len:  5466512 \n",
      "Col coords len:  5466512 \n",
      "Data len:  5466512\n",
      "Row coords len:  10040512 \n",
      "Col coords len:  10040512 \n",
      "Data len:  10040512\n",
      "Row coords len:  12943583 \n",
      "Col coords len:  12943583 \n",
      "Data len:  12943583\n",
      "Row coords len:  14960782 \n",
      "Col coords len:  14960782 \n",
      "Data len:  14960782\n",
      "Row coords len:  16261268 \n",
      "Col coords len:  16261268 \n",
      "Data len:  16261268\n",
      "Row coords len:  17209729 \n",
      "Col coords len:  17209729 \n",
      "Data len:  17209729\n",
      "Row coords len:  18077694 \n",
      "Col coords len:  18077694 \n",
      "Data len:  18077694\n",
      "Row coords len:  18840487 \n",
      "Col coords len:  18840487 \n",
      "Data len:  18840487\n",
      "Row coords len:  19186392 \n",
      "Col coords len:  19186392 \n",
      "Data len:  19186392\n",
      "Row coords len:  19576086 \n",
      "Col coords len:  19576086 \n",
      "Data len:  19576086\n",
      "Row coords len:  20262225 \n",
      "Col coords len:  20262225 \n",
      "Data len:  20262225\n",
      "Row coords len:  21033047 \n",
      "Col coords len:  21033047 \n",
      "Data len:  21033047\n",
      "Row coords len:  21609053 \n",
      "Col coords len:  21609053 \n",
      "Data len:  21609053\n",
      "Row coords len:  22008403 \n",
      "Col coords len:  22008403 \n",
      "Data len:  22008403\n",
      "Row coords len:  22339928 \n",
      "Col coords len:  22339928 \n",
      "Data len:  22339928\n",
      "Row coords len:  22570892 \n",
      "Col coords len:  22570892 \n",
      "Data len:  22570892\n",
      "Row coords len:  22798741 \n",
      "Col coords len:  22798741 \n",
      "Data len:  22798741\n",
      "Row coords len:  23036742 \n",
      "Col coords len:  23036742 \n",
      "Data len:  23036742\n",
      "Row coords len:  23269452 \n",
      "Col coords len:  23269452 \n",
      "Data len:  23269452\n",
      "Row coords len:  23447589 \n",
      "Col coords len:  23447589 \n",
      "Data len:  23447589\n",
      "Row coords len:  23644037 \n",
      "Col coords len:  23644037 \n",
      "Data len:  23644037\n",
      "Row coords len:  23866640 \n",
      "Col coords len:  23866640 \n",
      "Data len:  23866640\n",
      "Row coords len:  23966457 \n",
      "Col coords len:  23966457 \n",
      "Data len:  23966457\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we have 3 DFs, two of which correspond to user ratings: users_df, ratings_df. Lets combine them.\n",
    "We have movies_df, which has all the movie IDs, so make a column for each movie ID to users_df\n",
    "and include the rating if the user has rated it.\n",
    "It takes awhile to run, longer if you give it a quiet=False so that it reports progress\n",
    "to not appear stlled. After, save the sparse coords and data as a numpy.\n",
    "'''\n",
    "# The store_ratings_for_mov_id_as_sparse_coords method builds a sparse matrix\n",
    "# coordinates into 3 long arrays and those are saved to be loaded in later.\n",
    "# store_ratings_for_mov_id_as_sparse_coords just returns the movie_id it is given.\n",
    "movie_ids_series = movies_df[MOVIE_LENS_25M_MOVIE_ID_COL].map(\n",
    "    lambda movie_id: sparse_mat_maker.store_ratings_for_mov_id_as_sparse_coords(\n",
    "        movie_id,\n",
    "        ratings_df,\n",
    "        reindexer,\n",
    "        quiet=True))\n",
    "\n",
    "sparse_mat_maker.save_sparse_mat_coords(PATH_TO_PROCESSED_RATINGS_DATA)\n",
    "print(\"Finshed and saved ratings matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Goal is to have the number 0 be \"not specified\" or \"no rating\" and\n",
    "need to encode F vs M numerically, so using 1 vs -1, instead of 1 vs 0.\n",
    "Also, there are some zip codes that are like 12345-6789 and I want them to just be able\n",
    "to be straight numbers, so truncate the -6789 from the zip codes that are like that.\n",
    "After that, we finally have our users matrix, so save it as a numpy.\n",
    "'''\n",
    "users_df[MOVIE_LENS_1M_GENDER_COL] = users_df[MOVIE_LENS_1M_GENDER_COL].map(\n",
    "    lambda g: 1 if g == \"F\" else -1)\n",
    "\n",
    "users_df[MOVIE_LENS_1M_ZIPCODE_COL] = users_df[MOVIE_LENS_1M_ZIPCODE_COL].map(drop_zipcode_tail)\n",
    "\n",
    "np.savez(PATH_TO_PROCESSED_USERS_DATA, users_matrix=users_df.to_numpy(dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iterate over the genres of each movie and get a one-hot encoding representation,\n",
    "then make it into a DF and concat the results to the end of the DF with the movie titles\n",
    "'''\n",
    "movies_df[MOVIE_LENS_25M_MOVIE_GENRES_COL] = movies_df[MOVIE_LENS_25M_MOVIE_GENRES_COL].map(\n",
    "    lambda gs: genres_to_one_hot(gs, '|', MOVIE_LENS_GENRES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "The movie titles have years tacked on the ends of them, with some parenths.\n",
    "Take these off, then insert them as their own column of \"numbers\" for the matrix\n",
    "of numbers we are building.\n",
    "'''\n",
    "year_accumulator = []\n",
    "movies_df[MOVIE_LENS_25M_MOVIE_TITLE_COL] = movies_df[MOVIE_LENS_25M_MOVIE_TITLE_COL].apply(\n",
    "    lambda title: accumulate_year(year_accumulator, title))\n",
    "movies_df = pd.concat(\n",
    "    [movies_df, pd.DataFrame({YEAR_COL: year_accumulator})],\n",
    "    axis=1,\n",
    "    join=\"inner\")\n",
    "\n",
    "'''\n",
    "Found some bad chars in the year column of our movies_df.\n",
    "Filter these out manually so we have just a column of strings that can be converted to ints without issue.\n",
    "'''\n",
    "movies_df[YEAR_COL] = movies_df[YEAR_COL].map(lambda year: year.replace(\"L'Associe\", \"\"))\n",
    "movies_df[YEAR_COL] = movies_df[YEAR_COL].map(lambda year: year.replace(')', \"\"))\n",
    "movies_df[YEAR_COL] = movies_df[YEAR_COL].map(lambda year: year.replace('(', \"\"))\n",
    "movies_df[YEAR_COL] = movies_df[YEAR_COL].map(lambda year: year.split('-')[0])\n",
    "movies_df[YEAR_COL] = movies_df[YEAR_COL].map(lambda year: year.split('–')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we have to do some word embedding. Make a glove that was trained on Twitter object.\n",
    "'''\n",
    "embedded_vector_len = 25 # There is 25, 50, 100, 200\n",
    "glove = Glove(PATH_TO_GLOVE, embedded_vector_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, need to inspect the tags, clean them so that they are only words seperated by spaces.\n",
    "Then, either throw out duplicate movie ID tags or combine all tags that are for the same movie id. \n",
    "Then find the tag with the most words and call that the number of vectors we need to make for each movie.\n",
    "'''\n",
    "tags_df = pd.read_csv(PATH_TO_MOVIE_LENS_25M_TAGS)\n",
    "tags_df[MOVIE_LENS_25M_TAG_COL] = tags_df[MOVIE_LENS_25M_TAG_COL].map(glove.clean_str)\n",
    "tags_df = tags_df.drop_duplicates(subset=[MOVIE_LENS_25M_MOVIE_ID_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  4,  3,  9,  6,  5, 15,  7, 16, 10,  8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Find that there are some really long tags. Need to make an equal number of vectors for each movie.\n",
    "'''\n",
    "glove_vects_per_movie = tags_df[MOVIE_LENS_25M_TAG_COL].map(lambda tag: len(tag.split())).unique()\n",
    "glove_vects_per_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make a version of the tags where even movies without tags have a row that is just the empty string\n",
    "'''\n",
    "movie_id_reindexer = movies_df[MOVIE_LENS_25M_MOVIE_ID_COL].to_numpy()\n",
    "tags_df_mut = tags_df.set_index(MOVIE_LENS_25M_MOVIE_ID_COL)\n",
    "tags_df_mut = tags_df_mut.reindex(movie_id_reindexer, fill_value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Don't want to make so many glove embeddings, so will only embed the first certain number\n",
    "of tokens for those movies with tags.\n",
    "Embed the tag for each movie. Some of this is just embedding \"\", which will\n",
    "return an embedding of all 0s.\n",
    "'''\n",
    "num_of_toks_to_embed = 6\n",
    "embedded_col = tags_df_mut[MOVIE_LENS_25M_TAG_COL].map(lambda tag: glove.embed_str(tag, num_of_toks_to_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tack it onto the end of the movies_df\n",
    "'''\n",
    "movies_df = movies_df.set_index(MOVIE_LENS_25M_MOVIE_ID_COL)\n",
    "movies_df = movies_df.join(embedded_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now clean and embed the movie titles\n",
    "'''\n",
    "movies_df[MOVIE_LENS_25M_MOVIE_TITLE_COL] = movies_df[MOVIE_LENS_25M_MOVIE_TITLE_COL].map(\n",
    "    glove.clean_str).map(lambda title: glove.embed_str(title, num_of_toks_to_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.5956, -0.67774, 0.63825, -0.55081, 0.3310...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[[-0.16845, 0.39337, 0.24115, -1.2381, 0.06361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.10984, -0.72454, 1.212, -0.16188, -0.77879...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[[-0.36034, -0.16173, 0.52871, 0.1684, -1.0275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.63078, 0.23414, 1.0839, -0.4605, 0.36985,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[[0.42466, -0.23493, 0.67394, -0.51295, 0.6706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.94693, 1.202, 0.68523, -0.13582, -0.76029...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[[0.57621, -0.0097165, -0.8488, -0.4566, 0.643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[-1.2006, 0.59454, 0.27821, 0.86424, 0.021296...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[[-0.86323, -0.13674, -1.2718, 0.67397, 1.0864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62962</th>\n",
       "      <td>213101</td>\n",
       "      <td>[[-0.95787, -1.298, 0.021577, 0.48332, 0.71122...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1954</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62963</th>\n",
       "      <td>213106</td>\n",
       "      <td>[[-0.95826, 0.34048, 0.51397, -0.22547, -0.069...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1973</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62964</th>\n",
       "      <td>213107</td>\n",
       "      <td>[[-0.42776, -0.097852, 0.54833, 0.20915, -0.18...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1943</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62965</th>\n",
       "      <td>213110</td>\n",
       "      <td>[[-1.9711, 0.44933, 0.57468, 0.39935, -0.04219...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1987</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62966</th>\n",
       "      <td>213111</td>\n",
       "      <td>[[-1.9711, 0.44933, 0.57468, 0.39935, -0.04219...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1990</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62967 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                              title  \\\n",
       "0            1  [[-0.5956, -0.67774, 0.63825, -0.55081, 0.3310...   \n",
       "1            2  [[0.10984, -0.72454, 1.212, -0.16188, -0.77879...   \n",
       "2            3  [[-0.63078, 0.23414, 1.0839, -0.4605, 0.36985,...   \n",
       "3            4  [[-0.94693, 1.202, 0.68523, -0.13582, -0.76029...   \n",
       "4            5  [[-1.2006, 0.59454, 0.27821, 0.86424, 0.021296...   \n",
       "...        ...                                                ...   \n",
       "62962   213101  [[-0.95787, -1.298, 0.021577, 0.48332, 0.71122...   \n",
       "62963   213106  [[-0.95826, 0.34048, 0.51397, -0.22547, -0.069...   \n",
       "62964   213107  [[-0.42776, -0.097852, 0.54833, 0.20915, -0.18...   \n",
       "62965   213110  [[-1.9711, 0.44933, 0.57468, 0.39935, -0.04219...   \n",
       "62966   213111  [[-1.9711, 0.44933, 0.57468, 0.39935, -0.04219...   \n",
       "\n",
       "                                                  genres  year  \\\n",
       "0      [0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  1995   \n",
       "1      [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  1995   \n",
       "2      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  1995   \n",
       "3      [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...  1995   \n",
       "4      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  1995   \n",
       "...                                                  ...   ...   \n",
       "62962  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  1954   \n",
       "62963  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  1973   \n",
       "62964  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  1943   \n",
       "62965  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  1987   \n",
       "62966  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  1990   \n",
       "\n",
       "                                                     tag  \n",
       "0      [[-0.16845, 0.39337, 0.24115, -1.2381, 0.06361...  \n",
       "1      [[-0.36034, -0.16173, 0.52871, 0.1684, -1.0275...  \n",
       "2      [[0.42466, -0.23493, 0.67394, -0.51295, 0.6706...  \n",
       "3      [[0.57621, -0.0097165, -0.8488, -0.4566, 0.643...  \n",
       "4      [[-0.86323, -0.13674, -1.2718, 0.67397, 1.0864...  \n",
       "...                                                  ...  \n",
       "62962  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "62963  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "62964  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "62965  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "62966  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[62967 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Now we can see it is all numbers.\n",
    "'''\n",
    "movies_df = movies_df.reset_index()\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Want to map over all movies rows and turn that into a row in sparse matrix, then save\n",
    "'''\n",
    "sparse_mat_maker.reset((True, lambda x: x == np.inf))\n",
    "movie_ids_series = movies_df.apply(\n",
    "    lambda series: sparse_mat_maker.make_movies_df_row_element_into_sparse_coords(series, quiet=True),\n",
    "    axis=1)\n",
    "sparse_mat_maker.save_sparse_mat_coords(PATH_TO_PROCESSED_MOVIES_DATA)\n",
    "\n",
    "'''\n",
    "Now there are 3 matrices:\n",
    "movies.npz, ratings.npz, users.npz\n",
    "movies.npz and ratings.nps are saved in sparse matrix format while users is not.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Will need to know some of the stuff we have here out in the other files where we load\n",
    "in the matrices, so save that all here to a specs json.\n",
    "'''\n",
    "num_columns_embedded = 2\n",
    "num_cols_one_encoded = 1\n",
    "movie_mat_col_cnt = (\n",
    "    len(movies_df.columns) - num_columns_embedded - num_cols_one_encoded) + (\n",
    "        (num_columns_embedded*(embedded_vector_len*num_of_toks_to_embed)) + MOVIE_LENS_NUM_GENRES)\n",
    "with open(PATH_TO_PROCESSED_DATA_SPECS, \"w\") as out_file:\n",
    "    out_file.write(\n",
    "        json.dumps(\n",
    "            {\n",
    "                SPEC_MOVIE_IDS: movies_df[MOVIE_LENS_25M_MOVIE_ID_COL].to_list(),\n",
    "                SPEC_USER_IDS: users_df[MOVIE_LENS_25M_USER_ID_COL].to_list(),\n",
    "                SPEC_MOVIES_MATRIX_COLUMN_COUNT: movie_mat_col_cnt\n",
    "            },\n",
    "            indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Recommender')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92d31e0efbf00df1d5e3cd24101558f8c3ad142afb5116f19cea238be2398bab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
